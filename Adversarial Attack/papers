1. Efficient Image-to-Image Diffusion Classifier for Adversarial Robustness
code: https://github.com/hfmei/IDC

It is an efficient diffusion model-based classifier for adversarial robustness, addressing the high computational cost of traditional DM-based defense methods.

(1) Redesigning the Diffusion Framework: Instead of generating high-quality images, the model is adapted to predict distinguishable image labels using an image translation framework that maps inputs to orthogonal image labels.
(2) Efficient Image-to-Image Diffusion Classifier: A pruned U-Net structure and reduced diffusion timesteps make the model computationally efficient while maintaining robustness.
(3) Optimized Classification Objective: A new classification loss is incorporated into the diffusion process to enhance class separability, improving adversarial robustness.
(4) Superior Performance with Lower Cost: Extensive evaluations on benchmark datasets show that the method achieves better adversarial robustness than both CNN-based and previous DM-based approaches, with significantly lower computational overhead.

2. A Sample-Level Evaluation and Generative Framework for Model Inversion Attacks
Model Inversion (MI) attack evaluation and effectiveness by introducing a new metric and a transfer learning framework to improve MI attack performance.

(1) Introduction of Diversity and Distance Composite Score (DDCS): A novel metric that enables sample-level privacy analysis, addressing the limitations of existing MI evaluation methods that focus only on label-level privacy.
(2) Key Observations from DDCS: The study finds that some training samples are naturally resilient to MI attacks, highlighting the varying vulnerability of individual samples.
(3) Transfer Learning for Stronger MI Attacks: Proposes an improved MI attack framework that enhances generative capabilities by integrating:
Entropy loss for better sample diversity.
Natural gradient descent to refine MI attack optimization.
(4) Improved Attack Performance: Extensive experiments show that the proposed method enhances state-of-the-art MI attacks, improving key metrics such as DDCS, coverage, and FID.
Potential for MI Defense: DDCS can also be used to identify vulnerable training samples, enabling unsupervised MI defense strategies.
